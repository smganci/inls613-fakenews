{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INLS 613: Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "\n",
    "1. Import Data\n",
    "2. Extract Features\n",
    "3. Split Train and Test\n",
    "4. Train Models\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fake_or_real_news.csv/fake_or_real_news.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1: Convert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing ### Importing a preprocessor to convert the labels in the target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_class_y= [ 'FAKE', 'REAL']\n",
    "le= preprocessing.LabelEncoder()\n",
    "le.fit(data_class_y)\n",
    "#y should now be an array of labels where 0 is FAKE and 1 is REAL\n",
    "y=le.transform(df['label']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2: Downcase text and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # lower takes in an array of strings and converts every string to all lower case\n",
    "# def lower(arr):\n",
    "#     out=[]\n",
    "#     for i in range(len(arr)):\n",
    "#         out.append(arr[i].lower())\n",
    "#     return out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_text=lower(df['text'])\n",
    "# lower_title=lower(df['title'])\n",
    "# lower_title[0:5]\n",
    "# #df['title'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tfidf:\n",
    "in: train x\n",
    "out: tfidf vectorizor, train_x_tfidf_array\"\"\"\n",
    "\n",
    "def to_train_x_tfidf_array (train_x, tf):\n",
    "#     tf = TfidfVectorizer(min_df=1,stop_words='english',max_features=max_feat, lowercase=True)\n",
    "    train_x_tfidf = tf.fit_transform(train_x)\n",
    "    train_x_tfidf_array = train_x_tfidf.toarray()\n",
    "    return train_x_tfidf_array\n",
    "\n",
    "\"\"\"\n",
    "create_feature_array:\n",
    "in: tf (tfidf vectorizor)\n",
    "out: array of features\"\"\"\n",
    "\n",
    "def create_feature_array(tf):\n",
    "    return np.array(tf.get_feature_names())\n",
    "\n",
    "\"\"\"\n",
    "sort_tfidf_array:\n",
    "in: array (train_x_tfidf)\n",
    "out: sorted array\"\"\"\n",
    "def sort_tfidf_array(train_x_tfidf):\n",
    "    return  np.argsort(train_x_tfidf).flatten()[::-1]\n",
    "\n",
    "\"\"\"\n",
    "top_n:\n",
    "in: tf (tfidf vectorizor), train_x_tfidf array, n (number of features)\n",
    "out: top_n features\"\"\"\n",
    "\n",
    "def top_n_features(tf, train_x_tfidf, n):\n",
    "    feature_array=create_feature_array(tf)\n",
    "    tfidf_sorting=sort_tfidf_array(train_x_tfidf)\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    return top_n\n",
    "    \n",
    "def title_convert(s):\n",
    "    String[] words = s.split;\n",
    "    for i in range(len(words)):\n",
    "        words[i]=\"title_\"+words[i]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_text, x_text= tfidf(lower_text, 5000)\n",
    "# x_text[0]\n",
    "# x_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_text = TfidfVectorizer(min_df=1,stop_words='english',max_features=500, lowercase=True)\n",
    "text_x_tfidf = tf_text.fit_transform(df['text'])\n",
    "text_x_tfidf_array = text_x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf_text.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top_n_text_features=top_n_features(tf_text, x_text, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_text[top_n_text_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_title = TfidfVectorizer(min_df=1,stop_words='english',max_features=500, lowercase=True, preprocessor= title_convert)\n",
    "title_x_tfidf = tf_title.fit_transform(df['title'])\n",
    "title_x_tfidf_array = title_x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '11',\n",
       " '16',\n",
       " '20',\n",
       " '2015',\n",
       " '2016',\n",
       " 'About',\n",
       " 'Access',\n",
       " 'Act',\n",
       " 'After',\n",
       " 'Against',\n",
       " 'Aleppo',\n",
       " 'All',\n",
       " 'America',\n",
       " 'American',\n",
       " 'Americans',\n",
       " 'An',\n",
       " 'And',\n",
       " 'Another',\n",
       " 'Anti',\n",
       " 'Arabia',\n",
       " 'Are',\n",
       " 'As',\n",
       " 'At',\n",
       " 'Attack',\n",
       " 'Attacks',\n",
       " 'Back',\n",
       " 'Be',\n",
       " 'Before',\n",
       " 'Behind',\n",
       " 'Bernie',\n",
       " 'Biden',\n",
       " 'Big',\n",
       " 'Bill',\n",
       " 'Black',\n",
       " 'Boehner',\n",
       " 'Bush',\n",
       " 'But',\n",
       " 'By',\n",
       " 'CLINTON',\n",
       " 'California',\n",
       " 'Calls',\n",
       " 'Campaign',\n",
       " 'Can',\n",
       " 'Carson',\n",
       " 'Case',\n",
       " 'Caught',\n",
       " 'Change',\n",
       " 'Children',\n",
       " 'China',\n",
       " 'Christian',\n",
       " 'Clinton',\n",
       " 'Clintons',\n",
       " 'Comey',\n",
       " 'Congress',\n",
       " 'Control',\n",
       " 'Could',\n",
       " 'Court',\n",
       " 'Cruz',\n",
       " 'DNC',\n",
       " 'DOJ',\n",
       " 'Daily',\n",
       " 'Dakota',\n",
       " 'Day',\n",
       " 'Dead',\n",
       " 'Deal',\n",
       " 'Debate',\n",
       " 'Democratic',\n",
       " 'Democrats',\n",
       " 'Dems',\n",
       " 'Department',\n",
       " 'Did',\n",
       " 'Director',\n",
       " 'Do',\n",
       " 'Don',\n",
       " 'Donald',\n",
       " 'Down',\n",
       " 'Election',\n",
       " 'Elections',\n",
       " 'Email',\n",
       " 'Emails',\n",
       " 'End',\n",
       " 'Europe',\n",
       " 'Exposed',\n",
       " 'FBI',\n",
       " 'Facebook',\n",
       " 'Family',\n",
       " 'Finds',\n",
       " 'Finest',\n",
       " 'Fiorina',\n",
       " 'First',\n",
       " 'Florida',\n",
       " 'For',\n",
       " 'Foreign',\n",
       " 'Found',\n",
       " 'Foundation',\n",
       " 'Fox',\n",
       " 'Francis',\n",
       " 'Fraud',\n",
       " 'From',\n",
       " 'GOP',\n",
       " 'Get',\n",
       " 'Go',\n",
       " 'Goes',\n",
       " 'Going',\n",
       " 'Gold',\n",
       " 'Got',\n",
       " 'Government',\n",
       " 'HILLARY',\n",
       " 'Hampshire',\n",
       " 'Has',\n",
       " 'Have',\n",
       " 'He',\n",
       " 'Health',\n",
       " 'Her',\n",
       " 'Here',\n",
       " 'High',\n",
       " 'Hillary',\n",
       " 'Him',\n",
       " 'His',\n",
       " 'History',\n",
       " 'House',\n",
       " 'How',\n",
       " 'Human',\n",
       " 'IN',\n",
       " 'ISIS',\n",
       " 'If',\n",
       " 'In',\n",
       " 'India',\n",
       " 'Information',\n",
       " 'Interview',\n",
       " 'Into',\n",
       " 'Investigation',\n",
       " 'Iowa',\n",
       " 'Iran',\n",
       " 'Iraq',\n",
       " 'Is',\n",
       " 'Islamic',\n",
       " 'Israel',\n",
       " 'It',\n",
       " 'James',\n",
       " 'Jeb',\n",
       " 'John',\n",
       " 'Johnson',\n",
       " 'Just',\n",
       " 'Kasich',\n",
       " 'Kelly',\n",
       " 'Killed',\n",
       " 'Know',\n",
       " 'Last',\n",
       " 'Law',\n",
       " 'Leaders',\n",
       " 'Left',\n",
       " 'Like',\n",
       " 'List',\n",
       " 'Lives',\n",
       " 'Look',\n",
       " 'Lost',\n",
       " 'Lynch',\n",
       " 'Make',\n",
       " 'Makes',\n",
       " 'Man',\n",
       " 'Marco',\n",
       " 'Matter',\n",
       " 'May',\n",
       " 'Media',\n",
       " 'Million',\n",
       " 'Money',\n",
       " 'More',\n",
       " 'Most',\n",
       " 'Mosul',\n",
       " 'Muslim',\n",
       " 'Muslims',\n",
       " 'My',\n",
       " 'NOT',\n",
       " 'NSA',\n",
       " 'National',\n",
       " 'Netanyahu',\n",
       " 'Never',\n",
       " 'New',\n",
       " 'News',\n",
       " 'Next',\n",
       " 'No',\n",
       " 'North',\n",
       " 'Not',\n",
       " 'November',\n",
       " 'Now',\n",
       " 'Nuclear',\n",
       " 'OF',\n",
       " 'Obama',\n",
       " 'Obamacare',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'Old',\n",
       " 'On',\n",
       " 'One',\n",
       " 'Onion',\n",
       " 'Only',\n",
       " 'Open',\n",
       " 'Opinion',\n",
       " 'Or',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Over',\n",
       " 'Own',\n",
       " 'Parenthood',\n",
       " 'Paris',\n",
       " 'Party',\n",
       " 'Paul',\n",
       " 'Pence',\n",
       " 'People',\n",
       " 'Pipeline',\n",
       " 'Plan',\n",
       " 'Podesta',\n",
       " 'Police',\n",
       " 'Political',\n",
       " 'Politics',\n",
       " 'Poll',\n",
       " 'Power',\n",
       " 'Presidency',\n",
       " 'President',\n",
       " 'Presidential',\n",
       " 'Probe',\n",
       " 'Public',\n",
       " 'Putin',\n",
       " 'Race',\n",
       " 'Rally',\n",
       " 'Real',\n",
       " 'Report',\n",
       " 'Republican',\n",
       " 'Republicans',\n",
       " 'Reveals',\n",
       " 'Right',\n",
       " 'Rights',\n",
       " 'Rock',\n",
       " 'Romney',\n",
       " 'Rubio',\n",
       " 'Run',\n",
       " 'Russia',\n",
       " 'Russian',\n",
       " 'Ryan',\n",
       " 'Sanders',\n",
       " 'Saudi',\n",
       " 'Say',\n",
       " 'Says',\n",
       " 'Secret',\n",
       " 'Security',\n",
       " 'Senate',\n",
       " 'Sex',\n",
       " 'She',\n",
       " 'Should',\n",
       " 'Show',\n",
       " 'So',\n",
       " 'Source',\n",
       " 'South',\n",
       " 'Speech',\n",
       " 'Standing',\n",
       " 'State',\n",
       " 'States',\n",
       " 'Stop',\n",
       " 'Street',\n",
       " 'Support',\n",
       " 'Supporters',\n",
       " 'Supreme',\n",
       " 'Syria',\n",
       " 'Syrian',\n",
       " 'THE',\n",
       " 'TO',\n",
       " 'Take',\n",
       " 'Team',\n",
       " 'Ted',\n",
       " 'Than',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Their',\n",
       " 'Them',\n",
       " 'There',\n",
       " 'They',\n",
       " 'Things',\n",
       " 'Think',\n",
       " 'This',\n",
       " 'Time',\n",
       " 'Times',\n",
       " 'To',\n",
       " 'Trump',\n",
       " 'Truth',\n",
       " 'TruthFeed',\n",
       " 'Tuesday',\n",
       " 'Twitter',\n",
       " 'Two',\n",
       " 'UN',\n",
       " 'US',\n",
       " 'United',\n",
       " 'Up',\n",
       " 'VIDEO',\n",
       " 'VP',\n",
       " 'Victory',\n",
       " 'Video',\n",
       " 'Violence',\n",
       " 'Vote',\n",
       " 'Voter',\n",
       " 'Voters',\n",
       " 'Voting',\n",
       " 'Wall',\n",
       " 'War',\n",
       " 'Was',\n",
       " 'Washington',\n",
       " 'Watch',\n",
       " 'Water',\n",
       " 'Way',\n",
       " 'We',\n",
       " 'Weiner',\n",
       " 'What',\n",
       " 'When',\n",
       " 'While',\n",
       " 'White',\n",
       " 'Who',\n",
       " 'Why',\n",
       " 'WikiLeaks',\n",
       " 'Wikileaks',\n",
       " 'Will',\n",
       " 'Win',\n",
       " 'Wins',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Women',\n",
       " 'Won',\n",
       " 'World',\n",
       " 'Would',\n",
       " 'Year',\n",
       " 'Years',\n",
       " 'Yemen',\n",
       " 'York',\n",
       " 'You',\n",
       " 'Your',\n",
       " 'amid',\n",
       " 'anti',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'battle',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'calls',\n",
       " 'campaign',\n",
       " 'candidates',\n",
       " 'case',\n",
       " 'change',\n",
       " 'claims',\n",
       " 'climate',\n",
       " 'com',\n",
       " 'conservative',\n",
       " 'control',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'election',\n",
       " 'email',\n",
       " 'emails',\n",
       " 'end',\n",
       " 'face',\n",
       " 'fight',\n",
       " 'foreign',\n",
       " 'future',\n",
       " 'government',\n",
       " 'history',\n",
       " 'immigration',\n",
       " 'just',\n",
       " 'killed',\n",
       " 'know',\n",
       " 'leaders',\n",
       " 'left',\n",
       " 'like',\n",
       " 'll',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'marriage',\n",
       " 'media',\n",
       " 'military',\n",
       " 'near',\n",
       " 'need',\n",
       " 'new',\n",
       " 'night',\n",
       " 'nomination',\n",
       " 'nuclear',\n",
       " 'party',\n",
       " 'people',\n",
       " 'plan',\n",
       " 'polarization',\n",
       " 'police',\n",
       " 'policy',\n",
       " 'political',\n",
       " 'politics',\n",
       " 'polls',\n",
       " 'president',\n",
       " 'presidential',\n",
       " 'primary',\n",
       " 'public',\n",
       " 'questions',\n",
       " 'race',\n",
       " 'real',\n",
       " 'really',\n",
       " 'report',\n",
       " 'reportedly',\n",
       " 'right',\n",
       " 'rules',\n",
       " 'run',\n",
       " 'say',\n",
       " 'says',\n",
       " 'second',\n",
       " 'shooting',\n",
       " 'shows',\n",
       " 'speech',\n",
       " 'state',\n",
       " 'stop',\n",
       " 'strategy',\n",
       " 'support',\n",
       " 'supporters',\n",
       " 'takeaways',\n",
       " 'takes',\n",
       " 'talks',\n",
       " 'terror',\n",
       " 'test',\n",
       " 'things',\n",
       " 'think',\n",
       " 'time',\n",
       " 'title_',\n",
       " 'title_5',\n",
       " 'title_A',\n",
       " 'title_After',\n",
       " 'title_As',\n",
       " 'title_BREAKING',\n",
       " 'title_Bernie',\n",
       " 'title_Can',\n",
       " 'title_Clinton',\n",
       " 'title_Comment',\n",
       " 'title_Cruz',\n",
       " 'title_Democratic',\n",
       " 'title_Donald',\n",
       " 'title_FBI',\n",
       " 'title_Former',\n",
       " 'title_GOP',\n",
       " 'title_Here',\n",
       " 'title_Hillary',\n",
       " 'title_House',\n",
       " 'title_How',\n",
       " 'title_ISIS',\n",
       " 'title_If',\n",
       " 'title_In',\n",
       " 'title_Iran',\n",
       " 'title_Is',\n",
       " 'title_It',\n",
       " 'title_Jeb',\n",
       " 'title_John',\n",
       " 'title_Netanyahu',\n",
       " 'title_New',\n",
       " 'title_Obama',\n",
       " 'title_Obamacare',\n",
       " 'title_Police',\n",
       " 'title_Poll',\n",
       " 'title_President',\n",
       " 'title_Putin',\n",
       " 'title_Re',\n",
       " 'title_Republicans',\n",
       " 'title_Russia',\n",
       " 'title_Sanders',\n",
       " 'title_State',\n",
       " 'title_Ted',\n",
       " 'title_The',\n",
       " 'title_This',\n",
       " 'title_Top',\n",
       " 'title_Trump',\n",
       " 'title_U',\n",
       " 'title_US',\n",
       " 'title_What',\n",
       " 'title_White',\n",
       " 'title_Why',\n",
       " 'title_Will',\n",
       " 'trade',\n",
       " 'truth',\n",
       " 've',\n",
       " 'victory',\n",
       " 'video',\n",
       " 'vote',\n",
       " 'voters',\n",
       " 'vs',\n",
       " 'want',\n",
       " 'war',\n",
       " 'white',\n",
       " 'win',\n",
       " 'wins',\n",
       " 'women',\n",
       " 'won',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_title.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_title, x_title=tfidf(lower_title, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n_title_features=top_n_features(tf_title, x_title, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['matters', 'jeb', 'bush', 'trump', 'final', 'ferguson', 'field',\n",
       "       'fight', 'fighting', 'financial', 'finally', 'feds', 'finds',\n",
       "       'finest', 'fiorina', 'fired', 'female', 'zika', 'flight', 'federal',\n",
       "       'fears', 'fear', 'fbi', 'far', 'fans', 'family', 'false', 'fall',\n",
       "       'fake', 'failure', 'failed', 'facts', 'fix', 'florida', 'faces',\n",
       "       'focus', 'gives', 'getting', 'gets', 'germany', 'george', 'general',\n",
       "       'gay', 'gas', 'gary', 'game', 'future', 'funding', 'french',\n",
       "       'freedom', 'free', 'fraud', 'francis', 'france', 'fox',\n",
       "       'foundation', 'forward', 'foreign', 'forces', 'forced', 'force',\n",
       "       'food', 'following', 'fact', 'face', 'facebook', 'dr', 'elect',\n",
       "       'economy', 'economic', 'easy', 'eastern', 'east', 'earth', 'early',\n",
       "       'duke', 'drugs', 'drops', 'drone', 'dream', 'donors', 'global',\n",
       "       'donald', 'don', 'dollar', 'doj', 'doing', 'dog', 'doesn', 'does',\n",
       "       'dnc', 'discovered', 'director', 'different', 'die', 'elected',\n",
       "       'election', 'elections', 'elites', 'extreme'], \n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_title_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'anti',\n",
       " 'attack',\n",
       " 'bernie',\n",
       " 'big',\n",
       " 'black',\n",
       " 'breaking',\n",
       " 'bush',\n",
       " 'calls',\n",
       " 'campaign',\n",
       " 'change',\n",
       " 'clinton',\n",
       " 'comey',\n",
       " 'comment',\n",
       " 'congress',\n",
       " 'court',\n",
       " 'cruz',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'debate',\n",
       " 'democratic',\n",
       " 'democrats',\n",
       " 'don',\n",
       " 'donald',\n",
       " 'election',\n",
       " 'email',\n",
       " 'emails',\n",
       " 'end',\n",
       " 'fbi',\n",
       " 'fight',\n",
       " 'foreign',\n",
       " 'gop',\n",
       " 'government',\n",
       " 'hillary',\n",
       " 'house',\n",
       " 'immigration',\n",
       " 'investigation',\n",
       " 'iran',\n",
       " 'isis',\n",
       " 'jeb',\n",
       " 'just',\n",
       " 'like',\n",
       " 'make',\n",
       " 'media',\n",
       " 'new',\n",
       " 'news',\n",
       " 'nuclear',\n",
       " 'obama',\n",
       " 'obamacare',\n",
       " 'party',\n",
       " 'paul',\n",
       " 'people',\n",
       " 'plan',\n",
       " 'police',\n",
       " 'political',\n",
       " 'politics',\n",
       " 'poll',\n",
       " 'president',\n",
       " 'presidential',\n",
       " 'putin',\n",
       " 'race',\n",
       " 'real',\n",
       " 'really',\n",
       " 'report',\n",
       " 'republican',\n",
       " 'republicans',\n",
       " 'right',\n",
       " 'rubio',\n",
       " 'russia',\n",
       " 'russian',\n",
       " 'sanders',\n",
       " 'say',\n",
       " 'says',\n",
       " 'senate',\n",
       " 'state',\n",
       " 'stop',\n",
       " 'supreme',\n",
       " 'syria',\n",
       " 'ted',\n",
       " 'things',\n",
       " 'time',\n",
       " 'trump',\n",
       " 'video',\n",
       " 'vote',\n",
       " 'voters',\n",
       " 'voting',\n",
       " 'war',\n",
       " 'watch',\n",
       " 'white',\n",
       " 'wikileaks',\n",
       " 'win',\n",
       " 'wins',\n",
       " 'won',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_title.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split_data splits up the data into training and test sets\n",
    "#it will return: train_x, test_x, train_y, test_y\n",
    "#example usage: train_x, test_x, train_y, test_y = split_data(df['text'],y)\n",
    "def split_data(x_features, y_class):\n",
    "    return train_test_split(x_features, y_class, train_size=.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df['text'], y, train_size=.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"fake: \"+train_y.tolist().count(\"0\")+\"real: \"+ train_y.tolist().count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2527, 1: 2541}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##counting distribution of classes in train\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 637, 1: 630}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##counting distribution of classes in test\n",
    "unique, counts = np.unique(test_y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4: Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0) # Check what this alpha value is. You have already learnt most of the math to understand this. \n",
    "mnb.fit(train_x_tfidf_array,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test Set Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
